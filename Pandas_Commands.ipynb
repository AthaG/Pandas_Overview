{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#in order to read data where separator is \\t means tab\n",
    "orders = pd.read_csv('http://bit.ly/chiporders', sep = '\\t')\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the separator is | and headers is not the first row of the table, so pass default indexes\n",
    "movieusers = pd.read_csv('http://bit.ly/movieusers', sep='|', header = None)\n",
    "movieusers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you want to put column names instead of default intexes\n",
    "column_names = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "movieusers1 = pd.read_csv('http://bit.ly/movieusers', sep = '|', names = column_names)\n",
    "movieusers1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is a classical csv file\n",
    "import pandas as pd\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.City.head()\n",
    "#this works as Series too. Instead of ufo['City']! Nice....Although it doesn`t work where a space after the first word comes\n",
    "#like for example in the column named: Colors Reported...\n",
    "#Or if that name is a build-in attribute of the DataFrame like ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can concatenate two Series! Nice!\n",
    "ufo.City.head() + ', ' + ufo.State.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign a new Series into the DataFrame\n",
    "ufo['Location'] = ufo.City + ', ' + ufo.State\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I want to describe only the genre\n",
    "movies.genre.describe()\n",
    "# or I can tell it to include the objects of the DataFrame and see description of all non-numerical types\n",
    "movies.describe(include = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cool tip: press shift+tab (multiple times to get it bigger) inside the parenthesis of a function to see which \n",
    "are the arguments it takes'''\n",
    "print(movies.shape)\n",
    "print(movies.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To rename some columns use:\n",
    "ufo.rename(columns = {'Shape Reported':'Shape_Reported'}, inplace = True)\n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rename all columns you can do this:\n",
    "ufo_cols = ['city', 'colors reported', 'shape reported', 'state', 'time', 'location']\n",
    "ufo.columns = ufo_cols\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can pass column names direct when I read the file, but I must explicitly say that header = 0.\n",
    "#That means that the header has some existing names and I want to change them.\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports', names = ufo_cols, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you want to replace all the columns` spaces with underscores and the columns are too many\n",
    "ufo.columns = ufo.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are to way to drop columns. Either this:\n",
    "ufo.drop(columns = ['location'], inplace = True)\n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or this: (Here you must clarify that this namestring that you are giving is on axis = 1 for columns. Axis = 0 is for rows)\n",
    "ufo.drop('Location', axis = 1, inplace = True)\n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more than one columns you can write:\n",
    "movieusers1.drop(['gender', 'occupation'], axis = 1, inplace = True)\n",
    "movieusers1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can do this:\n",
    "movieusers1.drop(columns = ['age', 'zip_code'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieusers1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To drop rows there are again two options. Either the one below or drop([1,2,3,4], axis = 0, inplace = True)\n",
    "movieusers1.drop(index = [1,4], inplace = True)\n",
    "movieusers1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To sort values in a DataFrame\n",
    "movies.title.sort_values()\n",
    "#or movies['title'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But you can define the order to descending too..With the sort method the underlying data are not affected as with drop etc.\n",
    "movies.title.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above was to sort the Series but you can sort the whole DataFrame by the Series\n",
    "movies.sort_values('title', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can sort the dataframe by two columns too. First the one and within that the second\n",
    "movies.sort_values(['star_rating', 'genre'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To filter in a dateframe to a given condition\n",
    "movies[movies.duration >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To filter the duration for example but take the genre. In fact take the genre where the duration is >= 200\n",
    "movies.loc[movies.duration >= 200, 'genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to multiple contitions in pandas, use & for and, | for or !!! Use parenthesis too. YOU DONT NEED LOC\n",
    "movies[(movies.duration >= 200) & ((movies.genre == 'Action') | (movies.genre == 'Drama'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the isin operator too \n",
    "movies[(movies.genre.isin(['Action', 'Horror'])) & (movies.star_rating >= 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read only these two columns from the file. You can use the index too: usecols = [0,4]\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings', usecols = ['genre', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through a dataframe by specific rows\n",
    "for index, row in ufo.iterrows():\n",
    "    print(index, row.State, row.City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to drop the non-numeric columns\n",
    "import numpy as np\n",
    "drinks_new = drinks.select_dtypes(include=[np.number])\n",
    "drinks_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make the city names uppercase\n",
    "ufo.City.str.upper().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see if a particular city is contained in the series\n",
    "ufo[ufo.State.str.contains('MN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the datatype of a dataframe and replace it\n",
    "drinks['beer_servings'] = drinks.beer_servings.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change the datatype before open a file\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry', dtype = {'beer_servings':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip = pd.read_csv('http://bit.ly/chiporders', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip.item_price.str.replace('$', '').astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to use 0 and 1 in machine learning model which represents the False and True\n",
    "chip.item_name.str.contains('Chicken').astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to groupby something you are looking for\n",
    "drinks.groupby('continent').beer_servings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.groupby('continent').beer_servings.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.groupby('continent').beer_servings.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.groupby('continent').beer_servings.agg(['count', 'min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of course you can calculate an aggregant for all columns grouped by one column\n",
    "drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magic function in iPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.groupby('continent').mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a series\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the appearence percentages of every genre\n",
    "movies.genre.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above is a series so you can use series methods too\n",
    "movies.genre.value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the number of unique values in the dataframe\n",
    "movies.genre.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to create a crosstab with the dataframe fields\n",
    "pd.crosstab(movies.genre, movies.content_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.duration.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.genre.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = pd.read_csv('http://bit.ly/uforeports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.isnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.notnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the number of missing values in the dataframe\n",
    "ufo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the exact rows with the missing values in a series\n",
    "ufo[ufo.City.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(how = 'all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.dropna(subset = ['State','Time'], how = 'all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To the below command missing values are excluded by default!!!\n",
    "ufo['Shape Reported'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how you include the NaN values to be counted\n",
    "ufo['Shape Reported'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the NaN values to a value\n",
    "ufo['Shape Reported'].fillna(value = 'COULD NOT TELL', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo['Shape Reported'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you set the index as country for example and not as a default number for each row, you can select a value by this index.\n",
    "drinks.set_index('country', inplace = True)\n",
    "drinks.loc['Brazil','beer_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To erase the name country from the position above\n",
    "drinks.index.name = None\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reset the indices as before and fetch the name country again as datacolumn\n",
    "drinks.index.name = 'country'\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.reset_index(inplace = True)\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.describe().loc['25%','spirit_servings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.set_index('country', inplace = True)\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.index.name = None\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts()['Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you take in alphabetical order\n",
    "drinks.continent.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.Series(['3000000', '40000', '35678'], index = ['Albania', 'Andorra', 'Angola'], dtype = int, name = 'Population')\n",
    "people\n",
    "drinks.beer_servings * people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To concatenate rows or columns of a dataframe to a series use axis to tell where you want the series to be concat\n",
    "pd.concat([drinks, people], sort = False, axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[:, 'City'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[:4,['City','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[:4,'City':'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.loc[ufo.City == 'Ithaca', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.iloc[:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep = True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(drinks.continent.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store continents as int in order to save space in memory and speed up computations like groupby\n",
    "# You CANNOT do that with Country, because every row has a unique country, so you will end up with more memory_usage!!!!\n",
    "drinks['continent'] = drinks.continent.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.memory_usage(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.continent.cat.codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = pd.DataFrame({'ID':[100,200,300,400], 'quality':['good', 'very good', 'good', 'excellent']})\n",
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.sort_values('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you transform the quality to category, you can filter by category like:\n",
    "prod['quality'] = prod.quality.astype('category', categories = ['good', 'very good', 'excellent'], ordered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.sort_values('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.loc[prod.quality > 'good', : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic Kaggle dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['Pclass','Parch']\n",
    "X = train.loc[:, feature_col]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Survived\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('http://bit.ly/kaggletest')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = test.loc[:, feature_col]\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_class = logreg.predict(X_new)\n",
    "new_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To quarantee the Passenger Id will always be the first column I must declare it as index. Apparently in dicts is not guaranted\n",
    "pd.DataFrame({'PassengerId':test.PassengerId, 'Survived': new_pred_class}).set_index('PassengerId').to_csv('kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save a pandas object like a DataFrame to disk you must pickled it(that`s the name)\n",
    "train.to_pickle('pickled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('pickled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Pandas tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get random sample from a file. Everytime you run it you take different rows\n",
    "ufo.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To stabilize the random sample you get every time:\n",
    "ufo.sample(n=3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get a percentage fraction of a stabilized random sample:\n",
    "ufo.sample(frac = 0.75, random_state = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to create dummy variables with pandas\n",
    "train['Sex_male'] = train.Sex.map({'female':0, 'male': 1})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can do it with top level function\n",
    "pd.get_dummies(train.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you create dummies you want k - 1 columns. E.g. you want only the female or the male column here\n",
    "pd.get_dummies(train.Sex, prefix = 'Sex').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is an example with more than two columns\n",
    "pd.get_dummies(train.Embarked, prefix = 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_dummies = pd.get_dummies(train.Embarked, prefix = 'Embarked').iloc[:,1:]\n",
    "train = pd.concat([train, embarked_dummies],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create dummies for multiple columns and drop the first columns of the dummies columns:\n",
    "train = pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let`s say we want to see only the hour. Find the dtype and since it`s a string, slice will do it\n",
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.str.slice(-5, -3).astype(int).head() #Slice 5 to three characters from the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the time column to datetime wiht pandas\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I can take only the hour easily or any other attribute of datatime\n",
    "ufo.Time.dt.hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.dt.weekday_name.head() #weekday_name will be replaced by day_name() in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.dt.dayofyear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a given string to datetime. Weekday_name will be replace by day_name() in the future\n",
    "birthday = pd.to_datetime('19/11/1983')\n",
    "birthday.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I can use these two timestamps as comparison. The colon at the end tell pandas to bring back all the rows\n",
    "ufo.loc[ufo.Time.dt.year == birthday.year, : ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can perform calculations. The one below is called deltatime object\n",
    "ufo.Time.max() - ufo.Time.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And you can see only the day for example\n",
    "(ufo.Time.max() - ufo.Time.min()).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magic function in iPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to show a basic plot of the sightings through years\n",
    "ufo['Year'] = ufo.Time.dt.year\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Year.value_counts().sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a dataset of movie reviewers (modifying the default parameter values for read_table)\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('http://bit.ly/movieusers', sep='|', header=None, names=user_cols, index_col = 'user_id')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see the duplicates in the dataframe. Returns true if one of the previous rows is identical\n",
    "users.zip_code.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can sum the True duplicates to see how much are they\n",
    "users.zip_code.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see how many rows is duplicates to the previous rows in the whole dataframe\n",
    "users.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see these 7 rows\n",
    "users.loc[users.duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[users.duplicated(keep = 'first'), :] #keep the first duplicated rows that you find and give me the ones below them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[users.duplicated(keep = 'last'), :] #keep the last rows you will find and give me the ones above them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the duplicated rows. That means both 7 previous and the ones below them\n",
    "users.loc[users.duplicated(keep = False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can drop duplicates and we can do it inplace if we like\n",
    "users.drop_duplicates(keep = 'first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we want to identify as duplicates those that are in a particular column of columns\n",
    "users.duplicated(subset = ['age', 'zip_code']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.drop_duplicates(subset = ['age', 'zip_code']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting missing values\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.content_rating.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want to see them\n",
    "movies[movies.content_rating.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the values in content_rating column\n",
    "movies.content_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to replase the 'NOT RATED' rows with nulls...use loc to not take a 'SettingWithCopyWarning'\n",
    "import numpy as np\n",
    "movies.loc[movies.content_rating == 'NOT RATED', 'content_rating'] = np.nan\n",
    "movies.content_rating.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#although in the below situation we still take this warning. That is because pandas is not sure if this is a copy of the df\n",
    "#or the actual df. In this case we must create a copy explicitly\n",
    "top_movies = movies.loc[movies.star_rating >= 9, :]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say we want to change the duration of the first row because we know is wrong\n",
    "top_movies.loc[0, 'duration'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Although we have used loc we take the warning. Use the copy() to bypass\n",
    "top_movies = movies.loc[movies.star_rating >= 9, :].copy()\n",
    "top_movies.loc[0, 'duration'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this won`t affect the df for sure\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how we change display options in pandas\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many rows are being displayed as default?\n",
    "pd.get_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means it displays the 30 first and the 30 last rows. What if I want to see all of them?\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to return to the previous default option\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the documentation on pandas options without having to search the web\n",
    "pd.describe_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.describe_option('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to reset everything to the default display option. The warning is about some default display that have been deprecated\n",
    "#thus can be ignored\n",
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to create a dataframe from scratch\n",
    "df = pd.DataFrame({'id':[100, 101, 102,], 'colour': ['red', 'green', 'red',],}, index = ['a', 'b', 'c',])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can create a df from a list of lists\n",
    "df1 = pd.DataFrame([[100, 'red'],[101, 'green'],[102, 'red']], columns = ['id', 'colour'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to convert a numpy array to a dataframe\n",
    "#create a numpy array with 4 rows, two columns with random values between 0 and 1\n",
    "import numpy as np\n",
    "arr = np.random.rand(4, 2)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(arr, columns = ['one', 'two'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df from scratch and use np.arrays for values\n",
    "#np.arange(100,110,1) I want an array from 100 to 110 and I want every value (that will be 10 at the end)\n",
    "#np.random.randint(60,101,10) i want an array with values from 60 with 60 to 101 without 101 and I want 10 of them\n",
    "df3 = pd.DataFrame({'students': np.arange(100,110,1), 'test': np.random.randint(60,101,10)})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i can declare an index too\n",
    "df3 = pd.DataFrame({'students': np.arange(100,110,1), 'test': np.random.randint(60,101,10)}).set_index('students')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to create a new Series put it into the df\n",
    "s = pd.Series(['dog', 'cat'], index = ['b', 'c'], name = 'animals')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, s], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to use the map method. You can do more with it but this is the more used one case\n",
    "train['Sex_num'] = train.Sex.map({'female':1, 'male':0})\n",
    "train.loc[:4, ['Sex', 'Sex_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what apply do as a series method and as a df method\n",
    "#let`s say we want to find the length of each row in the Name column\n",
    "train['Name_length'] = train.Name.apply(len)\n",
    "train.loc[0:4, ['Name', 'Name_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another example how to use apply. I want to round up the Fare column...I will do it with the np.ceil function\n",
    "import numpy as np\n",
    "train['Fare_ceil'] = train.Fare.apply(np.ceil)\n",
    "train.loc[:4, ['Fare', 'Fare_ceil']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another example. I want to extract the first name of each name in the Name column. I will do it with a function\n",
    "train.Name.str.split(',')\n",
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "train.Name.str.split(',').apply(get_element, position = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can do the same with a lambda function\n",
    "train.Name.str.split(',').apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the apply method as df method\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to find the max number for all the rows of some columns\n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want the max value for each row for each column\n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to know wich column is the largest in each row\n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(np.argmax, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applymap as a df method. This can be used to change the original df too.\n",
    "\n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv('http://bit.ly/smallstocks')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupby('Symbol').Close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a series with a multiindex\n",
    "ser = stocks.groupby(['Symbol', 'Date']).Close.mean()\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can unstack a multiindex series and will become a df\n",
    "ser.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can construct the exact df with the pivot_table function\n",
    "df = stocks.pivot_table(values = 'Close', index = 'Symbol', columns = 'Date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say i want from the ser all the AAPL data. You can do that with loc for a multiindex series\n",
    "ser.loc['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc['AAPL', '2016-10-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.loc[:, '2016-10-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and if you have unstacked the series to a df. All of the above can be written for the df.For example:\n",
    "df.loc['AAPL', '2016-10-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to set a multiindex\n",
    "stocks.set_index(['Symbol', 'Date'], inplace = True)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better sort the above\n",
    "stocks.sort_index(inplace = True)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now if I want to see the values of the first row\n",
    "stocks.loc[('AAPL', '2016-10-03'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or only the Close column`s value\n",
    "stocks.loc[('AAPL', '2016-10-03'), 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To take the values for two Symbols\n",
    "stocks.loc[(['AAPL', 'MSFT'], '2016-10-03'), 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or to see the values for multiple dates. It a two list in a tuple thing and everything in a list.....hehe\n",
    "stocks.loc[(['AAPL', 'MSFT'], ['2016-10-03','2016-10-04']), 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But if I want the values for two dates for all the Symbols, I have to go with slice(None)\n",
    "stocks.loc[(slice(None), ['2016-10-03','2016-10-04']), 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see how many unique cities are there in the df\n",
    "ufo.City.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can merge two df in one on a common id: pd.merge(df1, df2). There is no example dfs to reflect here\n",
    "#If you have two dfs with different names of id columns to merge on, you can use: pd.merge(df1, df2, left_on = ' ', right_on = ' ')\n",
    "#If in one df you try to join on the index, you use: pd.merge(df1, df2, left_index = True, right_on = ' '), in this situation the index\n",
    "#of the right column will take the place of the index of the merged df\n",
    "#If you want to join on the index of both dfs: pd.merge(df1, df2, left_index = True, right_index = True), in this case the index\n",
    "#of the merged df is the left df`s index\n",
    "#You can decide how you want to merge the dfs: pd.merge(df1,df2, how = 'inner') or 'outer' or 'left' or 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example DataFrame\n",
    "df = pd.DataFrame([[12, 25, 2017, 10], [1, 15, 2018, 11]],\n",
    "                  columns=['month', 'day', 'year', 'hour'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new: create a datetime column from the entire DataFrame\n",
    "pd.to_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the df has not only these columns.Create a datetime column from the subset of the df\n",
    "pd.to_datetime(df[['month', 'day', 'year', 'hour']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with this function you can overwrite the index\n",
    "df.index = pd.to_datetime(df[['month', 'day', 'year', 'hour']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
